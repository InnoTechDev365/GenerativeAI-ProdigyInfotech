{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ“˜ Task 03: Text Generation with Markov Chains\n",
        "\n",
        "This notebook demonstrates how to build a basic **Markov Chain-based text generator** that learns word transitions from a given corpus and uses them to produce **new semi-plausible sentences**.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install matplotlib markovify spacy nltk\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "import re\n",
        "from collections import defaultdict, Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import spacy\n",
        "\n",
        "nltk.download('gutenberg')\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“š Dataset: Shakespeare Corpus\n",
        "\n",
        "We'll use three Shakespeare plays from NLTK's Gutenberg corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nltk.corpus import gutenberg\n",
        "\n",
        "# Load texts\n",
        "hamlet = gutenberg.raw('shakespeare-hamlet.txt')\n",
        "macbeth = gutenberg.raw('shakespeare-macbeth.txt')\n",
        "caesar = gutenberg.raw('shakespeare-caesar.txt')\n",
        "\n",
        "# Clean function\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'--', ' ', text)\n",
        "    text = re.sub(r'\\[.*?\\]', '', text)\n",
        "    text = re.sub(r'\\b\\d+\\b', '', text)\n",
        "    return ' '.join(text.split())\n",
        "\n",
        "# Apply cleaning\n",
        "hamlet_clean = clean_text(hamlet)\n",
        "macbeth_clean = clean_text(macbeth)\n",
        "caesar_clean = clean_text(caesar)\n",
        "\n",
        "# Tokenize using spaCy\n",
        "doc = nlp(hamlet_clean + \" \" + macbeth_clean + \" \" + caesar_clean)\n",
        "sentences = [sent.text for sent in doc.sents if len(sent.text) > 5]\n",
        "joined_sentences = \" \".join(sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ§© Markov Chain Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MarkovChain:\n",
        "    def __init__(self, order=2):\n",
        "        self.order = order\n",
        "        self.model = defaultdict(list)\n",
        "\n",
        "    def train(self, text):\n",
        "        words = re.findall(r'\\b\\w+\\b', text.lower())\n",
        "        if len(words) < self.order:\n",
        "            raise ValueError(\"Text too short for this model.\")\n",
        "        for i in range(len(words) - self.order):\n",
        "            history = tuple(words[i:i + self.order])\n",
        "            next_word = words[i + self.order]\n",
        "            self.model[history].append(next_word)\n",
        "\n",
        "    def generate(self, length=50, seed=None):\n",
        "        if not self.model:\n",
        "            raise ValueError(\"Model not trained yet.\")\n",
        "\n",
        "        if seed:\n",
        "            seed_words = tuple(seed.lower().split())\n",
        "            if seed_words in self.model:\n",
        "                current = seed_words\n",
        "            else:\n",
        "                print(\"Seed not found, starting randomly.\")\n",
        "                current = random.choice(list(self.model.keys()))\n",
        "        else:\n",
        "            current = random.choice(list(self.model.keys()))\n",
        "\n",
        "        output = list(current)\n",
        "\n",
        "        for _ in range(length - self.order):\n",
        "            next_words = self.model.get(current)\n",
        "            if not next_words:\n",
        "                break\n",
        "            next_word = random.choice(next_words)\n",
        "            output.append(next_word)\n",
        "            current = tuple(output[-self.order:])\n",
        "        return ' '.join(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŽ¯ Train and Generate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create and train model\n",
        "mc = MarkovChain(order=2)\n",
        "mc.train(joined_sentences)\n",
        "\n",
        "# Generate sample text\n",
        "print(\"Generated Text (seeded):\")\n",
        "print(mc.generate(length=30, seed=\"the forest\"))\n",
        "\n",
        "print(\"\\nGenerated Text (random start):\")\n",
        "print(mc.generate(length=30))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“Š Optional: Visualize Word Transitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pick a history to analyze\n",
        "history_to_check = ('the', 'forest')\n",
        "\n",
        "# Count frequencies\n",
        "counts = Counter(mc.model.get(history_to_check, []))\n",
        "\n",
        "# Plot\n",
        "if counts:\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.bar(counts.keys(), counts.values(), color='teal')\n",
        "    plt.title(f\"Next word frequencies after: {history_to_check}\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(f\"No transitions found for {history_to_check}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
